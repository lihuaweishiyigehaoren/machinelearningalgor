- [ ] # KMeans


##### 无监督学习（聚类方法）



##### 聚类算法

聚类算法中，样本的属性主要由其在特征空间中的相对距离来表示，这使得距离的概念对于聚类非常重要。



##### 距离类型

- [ ] 欧式距离 

  点 x = (x<sub>1</sub>，……，x<sub>n</sub>)和 y = （y<sub>1</sub>，……，y<sub>n</sub>）之间的欧式距离为：
  $$
  d(x,y) = \sqrt{(x_1-y_1)^2+……+（x_n-y_n)^2}=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}
  $$

- [ ] 余弦距离（又称余弦相似性）

  两个向量间的余弦值可以通过使用欧几里德点积公式求出：
  $$
  cos(\Theta)= \frac{\sum_{i=1}^nA_i \times B_i}{\sqrt{\sum_{i=1}^n{A_i}^2} \times \sqrt{\sum_{i=1}^n{B_i}^2}}
  $$

  - -1 意味着两个向量指向的方向截然相反；
  - 1 表示他们的指向是完全相同的；
  - 0 表示它们之间是独立的；
  - [-1,1]之间的其他值则表示中间程度的相似性或相异性

- [ ] 曼哈顿距离

  ![曼哈顿距离](D:\usegit\github\machinelearningalgor\KMEANS\图片\曼哈顿距离.png)

​      从点（x<sub>1</sub>,y<sub>1</sub>)到点（x<sub>2</sub>,y<sub>2</sub>)，曼哈顿距离为：
$$
|x_1-y_1|+|y_1-y_2|
$$
当然，还存在其他很多距离表示方式；



##### 定义

KMeans 是一种聚类方法，k 是一个常数值，由使用者指定，这种算法负责将特征空间中的 n 个向量聚集到 k 个簇中。



##### 算法步骤

1. 用户确定 k 值，并将 n 个样本投射为特征空间（一般为欧式空间）中的 n 个点（k<=n)
2. 算法在这 n 个点中随机选取 k 个点，作为初始的“簇核心”
3. 分别计算每个样本点到 k 个簇核心的距离（这里的距离一般取欧氏距离或余弦距离），找到离该点最近的簇核心，将它归属到对应的簇
4. 所有点到归属到簇之后， n 个点就分为了 k 个簇。之后重新计算每个簇的中心（平均距离中心），将其定义为新的“簇核心”
5. 反复迭代步骤3-4，直到簇核心不再移动为止



##### 迭代的目标

KMeans的算法目标是使得簇内的平方和最小：

有 n 个样本（x<sub>1</sub>,x<sub>2</sub>,……，x<sub>n</sub>	)，每个都是 d 维实向量，KMeans聚类的目标是将它们分为 k 个簇(k<=n)，这些簇的表示为S=(S<sub>1</sub>,S<sub>2</sub>,……，S<sub>k</sub>)。
$$
min\sum_{i=1}^{k}\sum_{x \epsilon S_i}||x-u_i||^2 其中u_i是S_i的重心
$$

##### 分配

