# KNN

##### 有监督学习



##### 算法步骤：

![KNN](D:\usegit\github\machinelearningalgor\KNN\图片\KNN.png)

1. 算距离，如图，当一个新的样本进入，计算它与训练集中的每个样本的距离。特征变量连续时，欧氏距离作为距离度量；特征离散时，也可以用重叠度量或者其他指标作为距离，结合具体情况分析。
2. 找近邻：找到与未知对象距离最近的 k 个训练样本。
3. 做分类/回归：在这 k 个近邻中出现次数最多的类别作为未知对象的预测类别（**多数表决法**），或者是取 k 个近邻的目标值平均数，作为未知对象的预测结果。

##### 多数表决法问题：

如果训练样本的类别分布不均衡，出现频率较多的样本会主导预测结果



##### 这一问题解决办法

常见的一种是：不再简单计算 k 个近邻中的多数，而是同时考虑 k 个近邻中的距离，k 近邻中每一个样本的类别（或目标值）都以距离的倒数为权值，最后求全体加权结果。



##### k 的取值

通常情况下 ，k >1，但也不会太大，是一个较小的正整数，具体取何值最佳，则取决于训练数据和算法目标。

一般情况下，k 值越大，受噪声的影响越小；但 k 值越大，也越容易模糊类别之间的界限。如下图所示问题：



![KNN问题](D:\usegit\github\machinelearningalgor\KNN\图片\KNN问题.png)

k 的取值，直接影响算法的结果。



##### 超参数问题

超参数问题的优化方法（网格搜索法、随机搜索法、贝叶斯最优化法等）