# PCA

机器学习中，有时会出现这样的情况，在训练样本固定的情况下，特征维数增加到某一个临界点后，继续增加反而导致模型的预测能力减小——这叫做休斯现象



每个现实世界的事物，再用来进行机器学习训练和预测时，需要转化为一个**特征向量**



##### 本征维度

信号的本征维度描述了需要用来表示信号的变量数量。对于含有N个变量的信号而言，它的本征维度为M，M满足0 &le;M&le;N。

本征维度支出，许多高位数据集通过削减维度至低维空间，而不必丢失重要信息。



##### 降维的本质

学习一个映射函数 y = f(x),其中x表示原始的高维数据，y表示映射后的低维数据



##### 线性可分

D<sub>0</sub>和D<sub>1</sub>是n维欧式空间的两个点集，如果存在n维向量$\omega$

图片：



##### 超平面